{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ拡張を行う特徴抽出\n",
    "\n",
    "### たたみ込みベースに全結合分類期を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.layers import Dense, GlobalAveragePooling2D,Input\n",
    "import os.path,sys\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.callbacks\n",
    "from keras.applications import VGG16\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "N_CATEGORIES  = 20\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 16\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                 include_top=False,\n",
    "                 input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "\n",
    "\n",
    "mini_metadata = pd.read_csv('mini_metadata.csv',index_col=0)\n",
    "classes = list(mini_metadata[\"make_model\"].value_counts().index)\n",
    "classes = sorted(classes)\n",
    "classes_num = len(mini_metadata.groupby(\"make_model\"))\n",
    "\n",
    "base_dir = 'mini_pictures'\n",
    "\n",
    "train_dir = os.path.join(base_dir,'train')\n",
    "valid_dir = os.path.join(base_dir,'valid')\n",
    "test_dir = os.path.join(base_dir,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912 657\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dense, GlobalAveragePooling2D,Input\n",
    "\n",
    "\n",
    "pictures_files = os.listdir(train_dir)\n",
    "NUM_TRAINING = 0\n",
    "NUM_VALIDATION = 0\n",
    "for i in range(classes_num):\n",
    "    NUM_TRAINING += len(os.listdir(os.path.join(train_dir, pictures_files[i])))\n",
    "    NUM_VALIDATION += len(os.listdir(os.path.join(valid_dir, pictures_files[i])))\n",
    "print(NUM_TRAINING,NUM_VALIDATION)\n",
    "\n",
    "x = conv_base.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(N_CATEGORIES, activation='softmax')(x)\n",
    "model = Model(inputs=conv_base.input, outputs=predictions)\n",
    "\n",
    "# model = models.Sequential()\n",
    "# model.add(conv_base)\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(256, activation='relu'))\n",
    "# model.add(layers.Dense(classes_num, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                20500     \n",
      "=================================================================\n",
      "Total params: 15,260,500\n",
      "Trainable params: 15,260,500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights\n",
      "before freezing the conv base: 30\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights')\n",
    "print('before freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights\n",
      "after freezing the conv base: 30\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights')\n",
    "print('after freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 凍結されたたたみ込みベースを使ってモデル全体を訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1912 images belonging to 20 classes.\n",
      "Found 657 images belonging to 20 classes.\n",
      "Epoch 1/30\n",
      "119/119 [==============================] - 5931s 50s/step - loss: 2.6214 - acc: 0.2009 - val_loss: 1.8030 - val_acc: 0.4588\n",
      "Epoch 2/30\n",
      "119/119 [==============================] - 5654s 48s/step - loss: 0.9055 - acc: 0.7184 - val_loss: 0.6224 - val_acc: 0.8736\n",
      "Epoch 3/30\n",
      "119/119 [==============================] - 5655s 48s/step - loss: 0.2723 - acc: 0.9167 - val_loss: 0.2358 - val_acc: 0.9345\n",
      "Epoch 4/30\n",
      "119/119 [==============================] - 5651s 47s/step - loss: 0.1147 - acc: 0.9668 - val_loss: 0.0754 - val_acc: 0.9516\n",
      "Epoch 5/30\n",
      "119/119 [==============================] - 5637s 47s/step - loss: 0.0988 - acc: 0.9778 - val_loss: 0.0614 - val_acc: 0.9922\n",
      "Epoch 6/30\n",
      "119/119 [==============================] - 5627s 47s/step - loss: 0.0093 - acc: 0.9995 - val_loss: 0.1244 - val_acc: 0.9906\n",
      "Epoch 7/30\n",
      "119/119 [==============================] - 6356s 53s/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 0.9922\n",
      "Epoch 8/30\n",
      "119/119 [==============================] - 7414s 62s/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 0.9938\n",
      "Epoch 9/30\n",
      "119/119 [==============================] - 6013s 51s/step - loss: 6.2548e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9953\n",
      "Epoch 10/30\n",
      "119/119 [==============================] - 6089s 51s/step - loss: 3.7717e-04 - acc: 1.0000 - val_loss: 7.7702e-05 - val_acc: 0.9953\n",
      "Epoch 11/30\n",
      "119/119 [==============================] - 6047s 51s/step - loss: 2.6960e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 0.9953\n",
      "Epoch 12/30\n",
      "119/119 [==============================] - 6056s 51s/step - loss: 2.3509e-04 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 0.9891\n",
      "Epoch 13/30\n",
      "119/119 [==============================] - 7366s 62s/step - loss: 1.8001e-04 - acc: 1.0000 - val_loss: 2.4506e-04 - val_acc: 0.9953\n",
      "Epoch 14/30\n",
      " 21/119 [====>.........................] - ETA: 1:54:48 - loss: 2.1748e-04 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "#     rotation_range=40,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# 検証データは水増しするべきで無いことに注意\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,               #ターゲットディレクトリ\n",
    "    target_size=(IMAGE_SIZE,IMAGE_SIZE),   #全ての画像を256*256に変換\n",
    "    batch_size=BATCH_SIZE,           #バッチサイズ\n",
    "    class_mode='categorical',#損失関数としてcategorical_crossentropyを使用するため,\n",
    "    classes=classes          #他クラスラベルが必要\n",
    "    )\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    valid_dir,               #ターゲットディレクトリ\n",
    "    target_size=(IMAGE_SIZE,IMAGE_SIZE),   #全ての画像を256*256に変換\n",
    "    batch_size=BATCH_SIZE,           #バッチサイズ\n",
    "    class_mode='categorical',#損失関数としてcategorical_crossentropyを使用するため,\n",
    "    classes=classes          #他クラスラベルが必要\n",
    "    )\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=2e-5),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=NUM_TRAINING//BATCH_SIZE,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=NUM_VALIDATION//BATCH_SIZE,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('history_VGG16_mini_extended_2.json', 'w') as f:\n",
    "    json.dump(history.history, f)\n",
    "\n",
    "model.save('model/VGG16_mini_extended_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "f = open('history_VGG16_mini_extended_2.json', 'r')\n",
    "history = json.load(f)\n",
    "f.close()\n",
    "\n",
    "acc = history['acc']\n",
    "val_acc = history['val_acc']\n",
    "loss = history['loss']\n",
    "val_loss = history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "#正解率をプロット\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#損失値をプロット\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validatin loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ファインチューニング\n",
    "\n",
    "特徴抽出に用いられる凍結されたたたみ込みベースの出力層をいくつか解凍し、モデルの新しく追加された部分と、解凍した層の両方で訓練を行う\n",
    "\n",
    "* 訓練済みベースネットワークの最後にカスタムネットワークを追加する\n",
    "* ベースネットワークを凍結する\n",
    "* 追加した部分の訓練を行う\n",
    "* ベースネットワークの一部を解凍する\n",
    "* 凍結した層と追加した部分の訓練を同時に行う\n",
    "\n",
    "上で３つ目までが終わっているので、４の、たたみ込みベース(conv_base)を解凍し、その中に含まれる層を個別に凍結する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ファインチューニングを行うのは最後の２つか３つの層のみ!\n",
    "つまり、block4_poolまでの層は全て凍結される。\n",
    "\n",
    "block5_conv1,block5_conv2,block5_conv3の３つの層が訓練可能になる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(lr=1e-5),#学習率が低いのはファインチューニングを行う３つの層の変更を制限するため\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch=NUM_TRAINING//BATCH_SIZE,\n",
    "                             epochs=30,\n",
    "                             validation_data=validation_generator,\n",
    "                             validation_steps=NUM_VALIDATION//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('history_VGG16_mini_extended_fine2.json', 'w') as f:\n",
    "    json.dump(history.history, f)\n",
    "\n",
    "model.save('model/VGG16_mini_extended_fine2.h5')\n",
    "\n",
    "f = open('history_VGG16_mini_extended_fine2.json', 'r')\n",
    "history = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "acc = history['acc']\n",
    "val_acc = history['val_acc']\n",
    "loss = history['loss']\n",
    "val_loss = history['val_loss']\n",
    "\n",
    "epochs = range(1,len(acc)+1)\n",
    "\n",
    "#正解率をプロット\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#損失値をプロット\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validatin loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
